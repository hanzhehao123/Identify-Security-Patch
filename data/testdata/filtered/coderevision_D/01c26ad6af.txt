diff --git a/util/mmap-alloc.c b/util/mmap-alloc.c
index 223d66219c..24854064b4 100644
--- a/util/mmap-alloc.c
+++ b/util/mmap-alloc.c
@@ -82,38 +82,6 @@ size_t qemu_mempath_getpagesize(const char *mem_path)
     return qemu_real_host_page_size;
 }
 
-/*
- * Reserve a new memory region of the requested size to be used for mapping
- * from the given fd (if any).
- */
-static void *mmap_reserve(size_t size, int fd)
-{
-    int flags = MAP_PRIVATE;
-
-#if defined(__powerpc64__) && defined(__linux__)
-    /*
-     * On ppc64 mappings in the same segment (aka slice) must share the same
-     * page size. Since we will be re-allocating part of this segment
-     * from the supplied fd, we should make sure to use the same page size, to
-     * this end we mmap the supplied fd.  In this case, set MAP_NORESERVE to
-     * avoid allocating backing store memory.
-     * We do this unless we are using the system page size, in which case
-     * anonymous memory is OK.
-     */
-    if (fd == -1 || qemu_fd_getpagesize(fd) == qemu_real_host_page_size) {
-        fd = -1;
-        flags |= MAP_ANONYMOUS;
-    } else {
-        flags |= MAP_NORESERVE;
-    }
-#else
-    fd = -1;
-    flags |= MAP_ANONYMOUS;
-#endif
-
-    return mmap(0, size, PROT_NONE, flags, fd, 0);
-}
-
 static inline size_t mmap_guard_pagesize(int fd)
 {
 #if defined(__powerpc64__) && defined(__linux__)
@@ -136,6 +104,7 @@ void *qemu_ram_mmap(int fd,
     int prot;
     int flags;
     int map_sync_flags = 0;
+    int guardfd;
     size_t offset;
     size_t total;
     void *guardptr;
@@ -147,7 +116,30 @@ void *qemu_ram_mmap(int fd,
      */
     total = size + align;
 
-    guardptr = mmap_reserve(total, fd);
+#if defined(__powerpc64__) && defined(__linux__)
+    /* On ppc64 mappings in the same segment (aka slice) must share the same
+     * page size. Since we will be re-allocating part of this segment
+     * from the supplied fd, we should make sure to use the same page size, to
+     * this end we mmap the supplied fd.  In this case, set MAP_NORESERVE to
+     * avoid allocating backing store memory.
+     * We do this unless we are using the system page size, in which case
+     * anonymous memory is OK.
+     */
+    flags = MAP_PRIVATE;
+    if (fd == -1 || guard_pagesize == qemu_real_host_page_size) {
+        guardfd = -1;
+        flags |= MAP_ANONYMOUS;
+    } else {
+        guardfd = fd;
+        flags |= MAP_NORESERVE;
+    }
+#else
+    guardfd = -1;
+    flags = MAP_PRIVATE | MAP_ANONYMOUS;
+#endif
+
+    guardptr = mmap(0, total, PROT_NONE, flags, guardfd, 0);
+
     if (guardptr == MAP_FAILED) {
         return MAP_FAILED;
     }